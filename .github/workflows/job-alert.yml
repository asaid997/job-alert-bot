name: LinkedIn DevOps Job Alert

on:
  schedule:
    - cron: '0,15,30,45 5-21 * * *'  # Every 15 mins, 08:00-23:59 Athens time (UTC+3)
  workflow_dispatch:

jobs:
  scrape-and-notify:
    runs-on: ubuntu-latest
    container:
      image: mcr.microsoft.com/playwright/python:v1.44.0-focal
    env:
      TELEGRAM_BOT_API: ${{ secrets.TELEGRAM_BOT_API }}
      TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
      - name: List files before download
        run: |
          echo "Listing files before download:"
          ls -lR


      - name: Download previous jobs cache artifact
        uses: actions/download-artifact@v4
        with:
          name: jobs-cache
        continue-on-error: true

      - name: List files after download
        run: |
          echo "Listing files after download:"
          ls -lR
          cat jobs-cache/last_jobs.json || echo "[DEBUG] jobs-cache/last_jobs.json not found"
      - name: Install Playwright and requests
        run: |
          pip install playwright requests pytz
          playwright install chromium
      - name: Run job alert script
        run: python temp.py

      - name: Print jobs cache file before upload
        run: |
          echo "[DEBUG] Listing jobs-cache directory before upload:"
          ls -l jobs-cache || true
          echo "[DEBUG] Printing jobs-cache/last_jobs.json contents:"
          cat jobs-cache/last_jobs.json || echo "[DEBUG] jobs-cache/last_jobs.json not found"
      - name: Upload jobs cache artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: jobs-cache
          path: jobs-cache/last_jobs.json
      - name: Upload Playwright videos
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: playwright-videos
          path: playwright-videos/
